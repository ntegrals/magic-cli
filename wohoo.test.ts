import { CallbackManager } from "langchain/callbacks";
import { OpenAI } from "langchain/llms/openai";
import dotenv from "dotenv";

dotenv.config();

/**
 * The `run` function is an asynchronous function that initializes an instance of the `OpenAI` class and calls the `call` method to send a request to the OpenAI API.
 * @returns {Promise<void>}
 */
export const run = async () => {
  // To enable streaming, we pass in `streaming: true` to the LLM constructor.
  // Additionally, we pass in a `CallbackManager` with a handler set up for the `handleLLMNewToken` event.
  const chat = new OpenAI({
    openAIApiKey: process.env.OPENAI_API_KEY, // The OpenAI API key is retrieved from the environment variables using the `dotenv` package.
    maxTokens: 1000, // The maximum number of tokens to generate in the response.
    streaming: true, // Enables streaming mode for the OpenAI API.
    callbackManager: CallbackManager.fromHandlers({
      /**
       * The `handleLLMNewToken` function is an asynchronous function that handles the `LLMNewToken` event emitted by the `OpenAI` class.
       * @param {string} token - The token generated by the OpenAI API.
       * @returns {Promise<void>}
       */
      async handleLLMNewToken(token: string) {
        process.stdout.write(token); // Writes the generated token to the standard output stream.
      },
    }),
  });

  const response = await chat.call("Tell me a long joke."); // Sends a request to the OpenAI API to generate a response to the given prompt.
  console.log(response); // Logs the generated response to the console.
};

run(); // Calls the `run` function to start the program.
